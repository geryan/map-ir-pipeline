## Load your packages, e.g. library(targets).
source("./packages.R")

## Load your R files
tar_source()

## tar_plan supports drake-style targets and also tar_target()
tar_plan(
  # read in example infection resistance data
  tar_target(ir_data_path,
    "data/simulated-ir-data.csv",
    format = "file"
  ),
  ir_data_raw = read_csv(ir_data_path),

  # perform the emplogit on response, and do IHs transform
  ir_data = add_pct_mortality(ir_data_raw, no_dead, no_tested),

  # m = Number of rows of full **genotypic** data
  # n = Number of rows of full **phenotypic** data
  # m + n = Number of rows of full dataset

  # specify the details for the different models ahead of time
  # hyperparameters are hard coded internally inside these functions
  model_xgb = build_ir_xgboost(),
  model_rf = build_ir_rf(),
  model_bgam = build_ir_bgam(),
  model_list = list(
    xgb = model_xgb,
    rf = model_rf,
    bgam = model_bgam
  ),

  model_formula = construct_model_formula(ir_data, response = "pct_mortality"),

  # ---- outer loop ---- #

  # Outer Loop ----
  # Take a full dataset (N+M), then run 10 fold CV of the entire inner loop
  # Every time we run inner loop, pass in N* = N x 0.9, and M* = M x 0.9
  # Every time we run this we give it a prediction set
  # N x 0.1 and M x 0.1
  # We get out a set of out of sample predictions of length N
  # Which we can compare to the true data (y-hat vs y)
  # Run the inner loop one more time, to the full dataset, N+M,
  # Predictions are made back to every pixel of map + year (spatiotemporal)


  # ---- inner loop ---- #
  # We need to fit each of the L0 models, 11 times

  # this data is provided from the outer loop, not sure how this works yet
  # so am just writing some function to describe that
  ir_data_mn_star = get_data_from_outer_loop(),
  # m_star = Number of rows in each **inner loop** of **genotypic** data
  ir_data_m_star = ir_data_mn_star %>% filter(type == "genotypic"),
  # n_star = Number of rows in each **inner loop** of **phenotypic** data
  ir_data_n_star = ir_data_mn_star %>% filter(type == "phenotypic"),
  # m_star and n_star are generated by the outer loop

  # 10 times to get the 10 folds out of sample predictions
  ## The generalisation step
  # Train on 90% ((N* + M*) x 0.9), predict on 10% (N* x 0.1)

  test_train = create_test_train(
    data = ir_data_mn_star,
    # so we get equal test/training within type
    strata = type,
    n_folds = 10
  ),

  # this should be N* + M*
  train_data_mn_star = extract_training(test_train),
  # this should just be M*
  test_data_nstar = extract_test(test_train) %>% filter(type == "phenotypic"),

  # this should fit 10 models - preparing for out of sample (oos)
  zero_level_oos_mn_star = fit_zero_level_models(
    data = train_data_mn_star,
    formula = model_formula,
    models = model_list
  ),

  # these prediction vectors should happen on each list of `test_data`
  # these will be of length N*
  out_of_sample_predictions = predict_models(
    data = test_data_nstar,
    models = zero_level_oos_mn_star
  ),

  # this should fit 1 model, for in-sample
  # 1 time to the full dataset, fitting to N*+M* data.
  zero_level_in_sample = fit_zero_level_models(
    # this is being fit to the
    data = ir_data_mn_star,
    formula = model_formula,
    models = model_list
  ),

  # And predict to the N* phenotypic data points,
  # to get the in sample predictions
  # (once weâ€™ve determined the parameters of the L1 model)
  ## QUESTION: unsure what "once we've determined parameters of L1 model" means?
  in_sample_predictions = predict_models(
    data = ir_data_n_star,
    models = zero_level_in_sample
  ),

  # ---- the L1 models ---- #
  # Take the out of sample predictions for each of the models,
  # combine them together of length N*, into the fixed effects,
  # one per model (XBG, RF, BGAM)
  # A 3xN* matrix / AKA out of sample covariates?
  out_of_sample_covariates = combine_predictions(
    out_of_sample_predictions
  ),

  in_sample_covariates = combine_predictions(
    in_sample_predictions
  ),

  zero_level_covariate_names = names(out_of_sample_covariates),

  # this formula will have spatial terms and other features?
  gp_inla_formula = build_gp_inla_formula(
    data = zero_level_covariate_names,
    outcome = "pct_mortality"
  ),

  # Fit the whole L1 model to N* original data, using out of sample covariates
  gp_inla_data_n_star_oos = build_inla_data(
    ir_data = filter(ir_data_n_star, type == "phenotype"),
    # including the out of sample covariates
    covariate_data = oos_covariates
  ),

  # Fit the whole L1 model to N* original data, using out of sample covariates
  # oos = out of sample
  # super learner = L1 model
  super_learner_oos = gp_inla(data = gp_inla_data_n_star_oos,
                              formula = gp_inla_formula),

  # Finally, we make a prediction
  # But we switch out-of-sample L0 covariates for L0 **in-sample covariates**
  # that gives a prediction of length N*
  gp_inla_data_n_star_is = predict(
    data = in_sample_covariates,
    model = super_learner_oos
  )

)
